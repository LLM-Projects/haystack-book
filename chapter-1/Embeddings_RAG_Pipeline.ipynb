{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Create a improvised RAG Piepline with Embedders using Haystack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Install Haystack 2.0 using `pip`. Its enough to run it only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it for the first time alone\n",
    "# %%bash\n",
    "\n",
    "# !pip install haystack-ai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from getpass import getpass\n",
    "\n",
    "from haystack import Document\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "from haystack.components.embedders import OpenAITextEmbedder, OpenAIDocumentEmbedder\n",
    "from haystack.components.retrievers.in_memory import (\n",
    "    InMemoryEmbeddingRetriever,\n",
    ")\n",
    "\n",
    "from haystack import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering data\n",
    "\n",
    "For this example we will make use of [The Meal DB's API](https://www.themealdb.com/api.php). This provides a list of dishes and associated metadata. We make use of the required metadata and store those in the documents. Instead of collecting all the dishes we just get the dishes on the starting letter. Currently it's hard-coded to `p` but can be modified based on your interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore(embedding_similarity_function=\"cosine\")\n",
    "document_store_with_embedded_data = InMemoryDocumentStore(\n",
    "    embedding_similarity_function=\"cosine\"\n",
    ")\n",
    "\n",
    "baseURL = \"https://www.themealdb.com/api/json/v1/1/search.php?f=\"\n",
    "# alphabet = input(\"Enter your favourite alphabet: \")\n",
    "alphabet = 'p'\n",
    "\n",
    "# To handle user input\n",
    "if len(alphabet) > 0:\n",
    "    alphabet = alphabet[0]\n",
    "\n",
    "data = requests.get(url=baseURL + alphabet)\n",
    "data = data.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Documents\n",
    "\n",
    "After fetching the data in `json` format, we convert it into [`Documents`](https://github.com/deepset-ai/haystack/blob/main/haystack/dataclasses/document.py#L48) for further usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for i in range(len(data[\"meals\"])):\n",
    "    title = data[\"meals\"][i][\"strMeal\"]\n",
    "    instructions = data[\"meals\"][i][\"strInstructions\"]\n",
    "\n",
    "    documents.append(\n",
    "        Document(\n",
    "            content=\"Title: \" + title + \"\\nMaking Instructions: \" + instructions,\n",
    "            meta={\n",
    "                \"cuisine\": data[\"meals\"][i][\"strCategory\"]\n",
    "                + \" \"\n",
    "                + data[\"meals\"][i][\"strArea\"],\n",
    "                \"url\": data[\"meals\"][i][\"strYoutube\"],\n",
    "            },\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the OpenAI key from [here](https://platform.openai.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding & Storing the documents\n",
    "\n",
    "We create a [In Memory Document Store](https://docs.haystack.deepset.ai/docs/inmemorydocumentstore) and append the documents inside. A document store is nothing but a list of Documents grouped under a common name and avaiable to retrieve the closest match. `In-Memory` refers to making use of local system's memory compared to any external document store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore(embedding_similarity_function=\"cosine\")\n",
    "document_embedder = OpenAIDocumentEmbedder()\n",
    "documents_with_embeddings = document_embedder.run(documents=documents)[\"documents\"]\n",
    "print(\"Total of\", document_store.write_documents(documents_with_embeddings), \"appended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Pipeline\n",
    "\n",
    "We create a haystack [pipeline](https://docs.haystack.deepset.ai/docs/pipelines) to query the user's question and retrieve the closest matches based on [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity).\n",
    "A pipeline consists of various [components](https://docs.haystack.deepset.ai/docs/creating-pipelines#2-initialize-components) connected together.\n",
    "\n",
    "Then we need to provide the links between the components which create the flow of the pipeline. We create a alias name for the pipeline component so that it becomes easy to address them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_retrieval_pipeline = Pipeline()\n",
    "\n",
    "text_embedder = OpenAITextEmbedder()\n",
    "retriever = InMemoryEmbeddingRetriever(document_store=document_store, top_k=3)\n",
    "\n",
    "query_retrieval_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "query_retrieval_pipeline.add_component(\"retriever\", retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_retrieval_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "To run the pipeline we pass the `user_input` as a dictionary. If there are multiple inputs we use the alias name and pass the input based on the input type.\n",
    "\n",
    "Since this retrieves the list of documents we print the `top_k` here 3, documents that are nearest to the users query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"Enter the question: \")\n",
    "\n",
    "result = query_retrieval_pipeline.run(\n",
    "    {\n",
    "        \"text_embedder\": {\"text\": query},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Retriever with Embeddings Results:\\n\")\n",
    "for doc in result[\"retriever\"][\"documents\"]:\n",
    "    print(doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the pipeline created in YAML format\n",
    "\n",
    "The reason is hayhooks supports deployment of pipelines through YAML/YML format. Then save this file locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just in case you updated the pipeline just try to\n",
    "data = query_retrieval_pipeline.dumps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_file = open(\"tests/pipeline.yml\", \"w+\")\n",
    "pipeline_file.writelines(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow these steps:\n",
    "\n",
    "- Start the Docker Daemon then run this command: `docker run --rm -p 1416:1416 -e OPENAI_API_KEY=replace_with_your_key deepset/hayhooks:main`. Please don't kill this terminal or else server will be closed.\n",
    "- Then open `http://localhost:1416` to check if the server is running. Alternatively [try](https://docs.haystack.deepset.ai/docs/hayhooks#check-status) `hayhooks status` in a new terminal tab/window.\n",
    "- Then using the `/deploy` endpoint you can deploy the pipeline locally. Use the command: `hayhooks deploy path_to_pipeline_file.yml`.\n",
    "- After successful response: `curl http://localhost:1416/draw/pipeline_file_name --output pipeline_file_name.png`\n",
    "- Open in a new tab on browser: `http://localhost:1416/docs/#` to view all the available endpoints and their methods.\n",
    "- Run the pipeline: <TBD>\n",
    "- Clean up using `/undeploy` using the command `hayhooks undeploy pipeline_file_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
